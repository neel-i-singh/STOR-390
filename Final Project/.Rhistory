system("gfortran --version")
system("gfortran --version")
dir.create('~/.R')
file.create('~/.R/Makevars')
system("gfortran --version")
system("gfortran --version")
system("gfortran --version")
system("gfortran --version")
install.packages("gfortran")
install.packages("g4trn")
system("/opt/homebrew/bin/gfortran --version")
system("gfortran --version")
system("gfortran --version")
system("gfortran --version")
system("gfortran --version")
library(devtools)
install_github("tshmak/lassosum")
pkgbuild::check_build_tools(debug = TRUE)
library(devtools)
install_github("tshmak/lassosum")
library(devtools)
install_github("tshmak/lassosum")
pkgbuild::check_build_tools(debug = TRUE)
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
Sys.getenv("PATH")
system("sh --version")
Sys.getenv("PATH")
Sys.getenv("PATH")
system("sh --version")
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
system("make --version")
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
Sys.getenv("PATH")
Sys.getenv("PATH")
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
system("/usr/bin/make --version")
system("sh --version")
Sys.getenv("PATH")
system("sh --version")
Sys.getenv("PATH")
system("sh --version")
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
Sys.getenv("PATH")
system("gfortran --version")
system("make --version")
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
system("gfortran --version")
install.packages("/Users/nisingh/Downloads/lassosum_0.4.5.tar.gz", repos = NULL, type = "source")
library(lassosum)
# Load necessary libraries
library(data.table)
# Step 1: Load GWAS Summary Data
gwas_data <- fread("GWAS.csv")  # Load GWAS summary statistics
setwd('/Users/nisingh/Documents/GitHub/STOR-390/Final Project')
# Load necessary libraries
library(data.table)
library(lassosum)
# Step 1: Load GWAS Summary Data
gwas_data <- fread("GWAS.csv")  # Load GWAS summary statistics
# Step 1: Load GWAS Summary Data
gwas_data <- fread("GWAS.csv")  # Load GWAS summary statistics
# Standardize GWAS headers (if necessary)
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Convert effect sizes to beta (optional, if not provided as input)
# Calculate approximate beta from odds ratio (log(OR) is an approximation)
gwas_data[, beta := log(OR)]
ld_matrix <- fread("LD.csv", header = TRUE, row.names = 1)
# Step 2: Load LD Matrix
ld_matrix <- read.csv("LD.csv")
ld_matrix <- as.matrix(ld_matrix)  # Convert to matrix format
# Step 1: Load GWAS Summary Data
gwas_data <- read.csv("GWAS.csv")  # Load GWAS summary statistics
ld_matrix
# Step 3: Ensure SNP Alignment Between GWAS and LD Matrix
# Find common SNPs
common_snps <- intersect(gwas_data$SNP, rownames(ld_matrix))
common_snps
rownames(ld_matrix)
ld_matrix
# Step 3: Ensure SNP Alignment Between GWAS and LD Matrix
# Find common SNPs
common_snps <- intersect(gwas_data$SNP, rownames(ld_matrix))
# Step 3: Ensure SNP Alignment Between GWAS and LD Matrix
# Find common SNPs
common_snps <- intersect(gwas_data$SNP, ld_matrix[1,]))
# Step 3: Ensure SNP Alignment Between GWAS and LD Matrix
# Find common SNPs
common_snps <- intersect(gwas_data$SNP, ld_matrix[1,])
common_snps
ld_matrix[1,]
colnames(ld_matrix)
# Step 3: Ensure SNP Alignment Between GWAS and LD Matrix
# Find common SNPs
common_snps <- intersect(gwas_data$SNP, colnames(ld_matrix))
# Filter GWAS data and LD matrix for common SNPs
gwas_data <- gwas_data[SNP %in% common_snps]
# Step 3: Ensure SNP Alignment Between GWAS and LD Matrix
# Find common SNPs
common_snps <- intersect(gwas_data$SNP, colnames(ld_matrix))
common_snps
gwas_data$SNP
# Verify alignment
if (!all(rownames(ld_matrix) == gwas_data$SNP)) {
stop("Mismatch in SNP order between GWAS data and LD matrix")
}
# Verify alignment
if (!all(rownames(ld_matrix) == gwas_data$SNP)) {
stop("Mismatch in SNP order between GWAS data and LD matrix")
}
# Verify alignment
if (!all(rownames(ld_matrix) == gwas_data$SNP)) {
stop("Mismatch in SNP order between GWAS data and LD matrix")
}
if (!all(rownames(ld_matrix) == gwas_data$SNP)) {
print("Mismatch in SNP order between GWAS data and LD matrix")
}
names(gwas_data)
# Load necessary libraries
library(data.table)
library(lassosum)
# Step 1: Load GWAS Summary Data
gwas_data <- read.csv("GWAS.csv")  # Load GWAS summary statistics
# Standardize GWAS headers (if necessary)
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Convert effect sizes to beta (optional, if not provided as input)
# Calculate approximate beta from odds ratio (log(OR) is an approximation)
# Step 2: Load LD Matrix
ld_matrix <- read.csv("LD.csv")
ld_matrix <- as.matrix(ld_matrix)  # Convert to matrix format
gwas_data$SE <- (log(gwas_data$CI_Upper) - log(gwas_data$CI_Lower)) / (2 * 1.96)
gwas_data$beta <- log(gwas_data$OR)
z_scores <- (gwas_data$beta / gwas_data$SE)
# Run Lassosum
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$OR,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix          # LD matrix
)
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$OR,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix          # LD matrix
)
# Load necessary libraries
library(data.table)
library(lassosum)
# Step 1: Load GWAS Summary Data
gwas_data <- read.csv("GWAS.csv")  # Load GWAS summary statistics
# Standardize GWAS headers (if necessary)
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Convert effect sizes to beta (optional, if not provided as input)
# Calculate approximate beta from odds ratio (log(OR) is an approximation)
# Step 2: Load LD Matrix
ld_matrix <- read.csv("LD.csv")
ld_matrix <- as.matrix(ld_matrix)  # Convert to matrix format
# Step 4: Prepare Inputs for Lassosum
gwas_data$SE <- (log(gwas_data$CI_Upper) - log(gwas_data$CI_Lower)) / (2 * 1.96)
gwas_data$beta <- log(gwas_data$OR)
z_scores <- (gwa
# Load necessary libraries
library(data.table)
# Load necessary libraries
library(data.table)
library(lassosum)
# Step 1: Load GWAS Summary Data
gwas_data <- read.csv("GWAS.csv")  # Load GWAS summary statistics
# Standardize GWAS headers (if necessary)
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Convert effect sizes to beta (optional, if not provided as input)
# Calculate approximate beta from odds ratio (log(OR) is an approximation)
# Step 2: Load LD Matrix
ld_matrix <- read.csv("LD.csv")
ld_matrix <- as.matrix(ld_matrix)  # Convert to matrix format
# Step 4: Prepare Inputs for Lassosum
gwas_data$SE <- (log(gwas_data$CI_Upper) - log(gwas_data$CI_Lower)) / (2 * 1.96)
gwas_data$beta <- log(gwas_data$OR)
z_scores <- (gwas_data$beta / gwas_data$SE)  # Standardized z-scores (if not already provided)
# Load necessary libraries
library(data.table)
library(lassosum)
# Step 1: Load GWAS Summary Data
gwas_data <- read.csv("GWAS.csv")  # Load GWAS summary statistics
# Standardize GWAS headers (if necessary)
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Convert effect sizes to beta (optional, if not provided as input)
# Calculate approximate beta from odds ratio (log(OR) is an approximation)
# Step 2: Load LD Matrix
ld_matrix <- read.csv("LD.csv")
ld_matrix <- as.matrix(ld_matrix)  # Convert to matrix format
# Step 4: Prepare Inputs for Lassosum
gwas_data$SE <- (log(gwas_data$CI_Upper) - log(gwas_data$CI_Lower)) / (2 * 1.96)
gwas_data$beta <- log(gwas_data$OR)
z_scores <- (gwas_data$beta / gwas_data$SE)  # Standardized z-scores (if not already provided)
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$OR,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix          # LD matrix
)
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$OR,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix,
ref.LDblocks = "single"     # LD matrix
)
# Load necessary libraries
library(data.table)
library(lassosum)
# Step 1: Load GWAS Summary Data
gwas_data <- read.csv("GWAS.csv")  # Load GWAS summary statistics
# Standardize GWAS headers (if necessary)
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Convert effect sizes to beta (optional, if not provided as input)
# Calculate approximate beta from odds ratio (log(OR) is an approximation)
# Step 2: Load LD Matrix
ld_matrix <- read.csv("LD.csv")
ld_matrix <- as.matrix(ld_matrix)  # Convert to matrix format
# Step 4: Prepare Inputs for Lassosum
gwas_data$SE <- (log(gwas_data$CI_Upper) - log(gwas_data$CI_Lower)) / (2 * 1.96)
gwas_data$beta <- log(gwas_data$OR)
z_scores <- (gwas_data$beta / gwas_data$SE)  # Standardized z-scores (if not already provided)
z_scores
all(rownames(ld_matrix) == colnames(ld_matrix))  # Should return TRUE
length(z_scores) == nrow(ld_matrix)  # Should return TRUE
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$beta,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix,
ref.LDblocks = "single"     # LD matrix
)
# Run Lassosum
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$beta,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix,
ref.LDblocks = "single"     # LD matrix
)
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$beta,          # Effect allele (dummy placeholder; not used by Lassosum but required)
ref.LD = ld_matrix,
ref.LDblocks = "single"     # LD matrix
)
results <- lassosum.pipeline(
cor = z_scores,             # Z-scores
chr = gwas_data$CHR,        # Chromosome numbers
pos = gwas_data$BP,         # Base pair positions
A1 = gwas_data$beta,        # Effect sizes
ref.LD = ld_matrix,         # LD matrix (correlation matrix)
ref.LDblocks = "single"     # Treat entire LD matrix as a single block
)
# Check alignment
all(rownames(ld_matrix) %in% gwas_data$SNP)  # Should return TRUE
rownames(ld_matrix) <- colnames(ld_matrix) <- gwas_data$SNP
library(glmnet)
gwas_data <- read.csv("GWAS.csv")
# Convert OR to beta
gwas_data$beta <- log(gwas_data$OR)
gwas_data$beta
# Step 1: Load the GWAS Data
gwas_data <- read.csv("GWAS.csv")  # Replace with your file path
ata) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Ensure headers are standardized
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Step 2: Calculate Beta (Effect Size) from Odds Ratio
gwas_data$beta <- log(gwas_data$OR)
# Step 3: Prepare Matrix for Elastic Net
# Use SNPs as predictors (X) and Z-scores as the target (y)
# Calculate Z-scores from beta and p-value
gwas_data$z_score <- sign(gwas_data$beta) * qnorm(1 - gwas_data$P / 2)
# Create the predictor matrix (X)
X <- model.matrix(~ CHR + BP - 1, data = gwas_data)  # SNP as features
# Target variable (Z-scores)
y <- gwas_data$z_score
fit <- cv.glmnet(
X, y,
alpha = 0.5,              # Elastic net mixing parameter
family = "gaussian",      # Use Gaussian regression for continuous Z-scores
standardize = TRUE        # Standardize predictors
)
# Step 5: Extract Coefficients
# Lambda with minimum mean cross-validated error
coef <- coef(fit, s = "lambda.min")
selected_snps <- rownames(coef)[coef != 0]
library(glmnet)
# Step 1: Load the GWAS Data
gwas_data <- read.csv("GWAS.csv")  # Replace with your file path
# Ensure headers are standardized
colnames(gwas_data) <- c("SNP", "CHR", "BP", "P", "OR", "CI_Lower", "CI_Upper")
# Step 2: Calculate Beta (Effect Size) from Odds Ratio
gwas_data$beta <- log(gwas_data$OR)
# Step 3: Prepare Matrix for Elastic Net
# Use SNPs as predictors (X) and Z-scores as the target (y)
# Calculate Z-scores from beta and p-value
gwas_data$z_score <- sign(gwas_data$beta) * qnorm(1 - gwas_data$P / 2)
# Create the predictor matrix (X)
X <- model.matrix(~ CHR + BP - 1, data = gwas_data)  # SNP as features
# Target variable (Z-scores)
y <- gwas_data$z_score
# Step 4: Fit Elastic Net
# Set alpha = 0.5 for elastic net (mix of ridge and lasso)
fit <- cv.glmnet(
X, y,
alpha = 0.5,              # Elastic net mixing parameter
family = "gaussian",      # Use Gaussian regression for continuous Z-scores
standardize = TRUE        # Standardize predictors
)
# Step 5: Extract Coefficients
# Lambda with minimum mean cross-validated error
coef <- coef(fit, s = "lambda.min")
# Identify selected SNPs and their coefficients
selected_snps <- rownames(coef)[coef != 0]
View(gwas_data)
coef_matrix <- as.matrix(coef(fit, s = "lambda.min"))
# Identify selected SNPs and their coefficients
selected_snps <- rownames(coef_matrix)[coef_matrix[, 1] != 0]
selected_snps <- selected_snps[selected_snps != "(Intercept)"]  # Exclude intercept
# Extract non-zero coefficients
selected_effects <- coef_matrix[coef_matrix[, 1] != 0, 1]
# Create a data frame with selected SNPs and their coefficients
results <- data.frame(SNP = selected_snps, Coefficient = selected_effects)
# Print results
print(results)
# Step 6: Save Results
# Save selected SNPs and their coefficients
write.csv(data.frame(SNP = selected_snps, Coefficients = selected_effects),
"elastic_net_results.csv", row.names = FALSE)
# Load necessary libraries
library(tidyverse)
# Load the data
summary_stats <- read.csv("GWAS.csv")
ld_matrix <- as.matrix(read.csv("LD.csv", row.names = 1))
selected_snps <- summary_stats %>%
filter(P < 5e-8 & CI_Lower > 1) %>% # Significant SNPs with CI excluding 1
arrange(P) # Rank by p-value
pruned_snps <- c()  # To store pruned SNPs
for (snp in selected_snps$SNP) {
# Check if SNP is independent of already pruned SNPs
if (all(ld_matrix[snp, pruned_snps] < 0.1, na.rm = TRUE)) {
pruned_snps <- c(pruned_snps, snp)
}
}
# Subset the pruned SNPs
pruned_summary <- selected_snps %>%
filter(SNP %in% pruned_snps)
pruned_summary <- pruned_summary %>%
mutate(Weight = log(OR))
genotypes <- data.frame(
Individual = 1:5, # Replace with individual IDs
rs1 = c(0, 1, 2, 0, 1), # Replace SNP column names with actual SNP IDs
rs2 = c(1, 0, 2, 2, 1)
)
prs <- genotypes %>%
rowwise() %>%
mutate(
PRS = sum(
c_across(all_of(pruned_summary$SNP)) * pruned_summary$Weight
)
)
# Load necessary libraries
library(tidyverse)
# Load the data
summary_stats <- read.csv("GWAS.csv")
ld_matrix <- as.matrix(read.csv("LD.csv", row.names = 1))
# SNP Selection Based on P-value and Confidence Interval
selected_snps <- summary_stats %>%
filter(P < 5e-8 & CI_Lower > 1) %>% # Significant SNPs with CI excluding 1
arrange(P) # Rank by p-value
# LD Pruning
pruned_snps <- c()  # To store pruned SNPs
for (snp in selected_snps$SNP) {
# Check if SNP is independent of already pruned SNPs
if (all(ld_matrix[snp, pruned_snps] < 0.1, na.rm = TRUE)) {
pruned_snps <- c(pruned_snps, snp)
}
}
# Subset the pruned SNPs
pruned_summary <- selected_snps %>%
filter(SNP %in% pruned_snps)
# Compute Weights (log(OR))
pruned_summary <- pruned_summary %>%
mutate(Weight = log(OR))
# Example Genotype Data (Simulated for Demonstration)
# Replace with real genotype data if available
genotypes <- data.frame(
Individual = 1:5, # Replace with individual IDs
rs1 = c(0, 1, 2, 0, 1), # Replace SNP column names with actual SNP IDs
rs2 = c(1, 0, 2, 2, 1)
)
# Compute PRS
prs <- genotypes %>%
rowwise() %>%
mutate(
PRS = sum(
c_across(all_of(pruned_summary$SNP)) * pruned_summary$Weight
)
)
pruned_summary$SNP
# Load necessary libraries
library(tidyverse)
# Load the data
summary_stats <- read.csv("GWAS.csv")
ld_matrix <- as.matrix(read.csv("LD.csv", row.names = 1))
# SNP Selection Based on P-value and Confidence Interval
selected_snps <- summary_stats %>%
filter(P < 5e-8 & CI_Lower > 1) %>% # Significant SNPs with CI excluding 1
arrange(P) # Rank by p-value
# LD Pruning
pruned_snps <- c()  # To store pruned SNPs
for (snp in selected_snps$SNP) {
# Check if SNP is independent of already pruned SNPs
if (all(ld_matrix[snp, pruned_snps] < 0.1, na.rm = TRUE)) {
pruned_snps <- c(pruned_snps, snp)
}
}
# Subset the pruned SNPs
pruned_summary <- selected_snps %>%
filter(SNP %in% pruned_snps)
# Compute Weights (log(OR))
pruned_summary <- pruned_summary %>%
mutate(Weight = log(OR))
# Example Genotype Data (Simulated for Demonstration)
# Replace with real genotype data if available
genotypes <- data.frame(
Individual = 1:5, # Replace with individual IDs
rs1 = c(0, 1, 2, 0, 1), # Replace SNP column names with actual SNP IDs
rs2 = c(1, 0, 2, 2, 1)
)
# Ensure SNP names match between genotype data and pruned SNPs
common_snps <- intersect(pruned_summary$SNP, colnames(genotypes))
# Subset the pruned summary statistics for these SNPs
pruned_summary <- pruned_summary %>%
filter(SNP %in% common_snps)
# Subset genotype data for the common SNPs
genotypes_subset <- genotypes %>%
select(Individual, all_of(common_snps))
# Match SNP order between genotypes and pruned summary
pruned_summary <- pruned_summary %>%
arrange(match(SNP, colnames(genotypes_subset)[-1])) # -1 to exclude Individual column
# Compute PRS
prs <- genotypes_subset %>%
rowwise() %>%
mutate(
PRS = sum(
c_across(all_of(common_snps)) * pruned_summary$Weight
)
) %>%
ungroup()
# Save the PRS
write.csv(prs, "PRS_results.csv", row.names = FALSE)
# Print final PRS for each individual
print(prs)
shiny::runApp('~/SchizophreniaOddsCalculator')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
library(shiny)
runExample("01_hello")
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
runApp('~/SchizoRiskCalc')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='neel-i-singh', token='D868F6134BDA711180CC7873D144186C', secret='pVFr3TCpYY7+2dhcJciHIFRUZspNGWUJsplg8pOe')
library(rsconnect)
rsconnect::deployApp(''/Users/nisingh/Documents/GitHub/STOR-390/Final Project/SchizophreniaRiskAssessmentTool.R'')
rsconnect::deployApp('/Users/nisingh/Documents/GitHub/STOR-390/Final Project/SchizophreniaRiskAssessmentTool.R')
rsconnect::deployApp('/Users/nisingh/Documents/GitHub/STOR-390/Final Project/SchizophreniaRiskAssessmentTool')
runApp('SchizophreniaRiskAssessmentTool')
runApp('SchizophreniaRiskAssessmentTool')
rsconnect::deployApp('/Users/nisingh/Documents/GitHub/STOR-390/Final Project/SchizophreniaRiskAssessmentTool')
